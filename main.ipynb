{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/'\n",
    "def readdata(path):\n",
    "    list_file = os.listdir(path)\n",
    "    data = pd.DataFrame()\n",
    "    for filename in list_file:\n",
    "        data = pd.concat([data, pd.read_csv(os.path.join(path, filename), sep = ',')])\n",
    "        \n",
    "    return data.Review, data.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews, labels = readdata(path)\n",
    "input_gensim = []\n",
    "for review in reviews:\n",
    "    input_gensim.append(review.split())\n",
    "    \n",
    "model = Word2Vec(input_gensim, vector_size=128, window=5, min_count=0, workers=4, sg=1)\n",
    "model.wv.save(\"word.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.keyedvectors as word2vec\n",
    "import numpy as np\n",
    "\n",
    "model_embedding = word2vec.KeyedVectors.load('./word.model')\n",
    "\n",
    "word_labels = list(model_embedding.key_to_index.keys())\n",
    "max_seq = 200\n",
    "embedding_size = model_embedding.vector_size  # Sử dụng kích thước vector thực tế từ mô hình\n",
    "\n",
    "def comment_embedding(comment):\n",
    "    matrix = np.zeros((max_seq, embedding_size))\n",
    "    words = comment.split()\n",
    "    lencmt = len(words)\n",
    "\n",
    "    for i in range(min(max_seq, lencmt)):\n",
    "        word = words[i]\n",
    "        if word in model_embedding.key_to_index:\n",
    "            matrix[i] = model_embedding[word]\n",
    "    \n",
    "    # Nếu comment ngắn hơn max_seq, phần còn lại của matrix sẽ là 0\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedded comment: (200, 128)\n"
     ]
    }
   ],
   "source": [
    "# Ví dụ sử dụng\n",
    "example_comment = \"Đây là một ví dụ comment\"\n",
    "embedded_comment = comment_embedding(example_comment)\n",
    "print(f\"Shape of embedded comment: {embedded_comment.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9727/9727 [00:00<00:00, 10275.57it/s]\n",
      "100%|██████████| 9727/9727 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "train_data = []\n",
    "label_data = []\n",
    "\n",
    "for x in tqdm(reviews):\n",
    "    train_data.append(comment_embedding(x))\n",
    "train_data = np.array(train_data)\n",
    "\n",
    "for y in tqdm(labels):\n",
    "    label_ = np.zeros(3)\n",
    "    try:\n",
    "        label_[int(y)] = 1\n",
    "    except:\n",
    "        label_[0] = 1\n",
    "    label_data.append(label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "sequence_length = 200\n",
    "embedding_size = 128\n",
    "num_classes = 3\n",
    "filter_sizes = 3\n",
    "num_filters = 150\n",
    "epochs = 50\n",
    "batch_size = 30\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">57,750</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m150\u001b[0m)    │        \u001b[38;5;34m57,750\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m150\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m150\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m19,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,465</span> (302.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m77,465\u001b[0m (302.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,465</span> (302.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m77,465\u001b[0m (302.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.reshape(train_data.shape[0], sequence_length, embedding_size, 1).astype('float32')\n",
    "y_train = np.array(label_data)\n",
    "\n",
    "# Define model\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Convolution2D(num_filters, (filter_sizes, embedding_size),\n",
    "                        padding='valid',\n",
    "                        input_shape=(sequence_length, embedding_size, 1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(198, 1)))\n",
    "model.add(layers.Dropout(dropout_rate))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "# Train model\n",
    "adam = tf.keras.optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.5405 - loss: 0.9373 - val_accuracy: 0.7663 - val_loss: 0.6350\n",
      "Epoch 2/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7219 - loss: 0.6958 - val_accuracy: 0.7157 - val_loss: 0.7153\n",
      "Epoch 3/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7358 - loss: 0.6571 - val_accuracy: 0.7863 - val_loss: 0.5570\n",
      "Epoch 4/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7575 - loss: 0.6082 - val_accuracy: 0.8173 - val_loss: 0.4901\n",
      "Epoch 5/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7661 - loss: 0.5929 - val_accuracy: 0.7830 - val_loss: 0.5855\n",
      "Epoch 6/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7700 - loss: 0.5649 - val_accuracy: 0.7983 - val_loss: 0.5214\n",
      "Epoch 7/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7934 - loss: 0.5398 - val_accuracy: 0.8103 - val_loss: 0.5370\n",
      "Epoch 8/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7959 - loss: 0.5210 - val_accuracy: 0.8080 - val_loss: 0.5020\n",
      "Epoch 9/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8043 - loss: 0.5062 - val_accuracy: 0.8320 - val_loss: 0.4260\n",
      "Epoch 10/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7955 - loss: 0.4997 - val_accuracy: 0.8293 - val_loss: 0.4374\n",
      "Epoch 11/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8134 - loss: 0.4683 - val_accuracy: 0.8520 - val_loss: 0.3838\n",
      "Epoch 12/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8092 - loss: 0.4775 - val_accuracy: 0.8497 - val_loss: 0.3913\n",
      "Epoch 13/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8161 - loss: 0.4553 - val_accuracy: 0.8613 - val_loss: 0.3620\n",
      "Epoch 14/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8288 - loss: 0.4388 - val_accuracy: 0.8717 - val_loss: 0.3595\n",
      "Epoch 15/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8258 - loss: 0.4274 - val_accuracy: 0.8750 - val_loss: 0.3763\n",
      "Epoch 16/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8365 - loss: 0.4196 - val_accuracy: 0.8767 - val_loss: 0.3163\n",
      "Epoch 17/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8350 - loss: 0.4178 - val_accuracy: 0.8673 - val_loss: 0.3441\n",
      "Epoch 18/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8392 - loss: 0.3939 - val_accuracy: 0.8877 - val_loss: 0.3321\n",
      "Epoch 19/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8355 - loss: 0.4139 - val_accuracy: 0.8763 - val_loss: 0.3321\n",
      "Epoch 20/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8423 - loss: 0.3879 - val_accuracy: 0.8973 - val_loss: 0.3424\n",
      "Epoch 21/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8556 - loss: 0.3858 - val_accuracy: 0.8917 - val_loss: 0.3400\n",
      "Epoch 22/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8510 - loss: 0.3768 - val_accuracy: 0.8860 - val_loss: 0.3031\n",
      "Epoch 23/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8629 - loss: 0.3583 - val_accuracy: 0.9097 - val_loss: 0.2479\n",
      "Epoch 24/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8574 - loss: 0.3654 - val_accuracy: 0.9167 - val_loss: 0.2842\n",
      "Epoch 25/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8604 - loss: 0.3530 - val_accuracy: 0.9167 - val_loss: 0.2681\n",
      "Epoch 26/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8578 - loss: 0.3555 - val_accuracy: 0.9290 - val_loss: 0.2242\n",
      "Epoch 27/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8578 - loss: 0.3422 - val_accuracy: 0.9303 - val_loss: 0.2563\n",
      "Epoch 28/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8670 - loss: 0.3333 - val_accuracy: 0.9210 - val_loss: 0.2469\n",
      "Epoch 29/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8657 - loss: 0.3406 - val_accuracy: 0.9273 - val_loss: 0.2061\n",
      "Epoch 30/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8661 - loss: 0.3367 - val_accuracy: 0.9363 - val_loss: 0.2454\n",
      "Epoch 31/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8740 - loss: 0.3089 - val_accuracy: 0.9323 - val_loss: 0.1924\n",
      "Epoch 32/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8819 - loss: 0.3005 - val_accuracy: 0.9203 - val_loss: 0.2814\n",
      "Epoch 33/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8695 - loss: 0.3311 - val_accuracy: 0.9377 - val_loss: 0.1897\n",
      "Epoch 34/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8837 - loss: 0.2971 - val_accuracy: 0.9560 - val_loss: 0.1836\n",
      "Epoch 35/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8820 - loss: 0.2886 - val_accuracy: 0.9440 - val_loss: 0.2018\n",
      "Epoch 36/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8778 - loss: 0.3017 - val_accuracy: 0.9580 - val_loss: 0.1685\n",
      "Epoch 37/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8819 - loss: 0.2968 - val_accuracy: 0.9587 - val_loss: 0.1796\n",
      "Epoch 38/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8813 - loss: 0.2948 - val_accuracy: 0.9527 - val_loss: 0.2142\n",
      "Epoch 39/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8901 - loss: 0.2850 - val_accuracy: 0.9557 - val_loss: 0.1686\n",
      "Epoch 40/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8894 - loss: 0.2832 - val_accuracy: 0.9623 - val_loss: 0.1546\n",
      "Epoch 41/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8898 - loss: 0.2801 - val_accuracy: 0.9650 - val_loss: 0.1489\n",
      "Epoch 42/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8960 - loss: 0.2630 - val_accuracy: 0.9563 - val_loss: 0.1629\n",
      "Epoch 43/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8850 - loss: 0.2934 - val_accuracy: 0.9570 - val_loss: 0.1732\n",
      "Epoch 44/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8950 - loss: 0.2653 - val_accuracy: 0.9630 - val_loss: 0.1300\n",
      "Epoch 45/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8975 - loss: 0.2714 - val_accuracy: 0.9610 - val_loss: 0.1715\n",
      "Epoch 46/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9077 - loss: 0.2503 - val_accuracy: 0.9547 - val_loss: 0.1562\n",
      "Epoch 47/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8890 - loss: 0.2625 - val_accuracy: 0.9723 - val_loss: 0.1183\n",
      "Epoch 48/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8977 - loss: 0.2547 - val_accuracy: 0.9653 - val_loss: 0.1437\n",
      "Epoch 49/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9028 - loss: 0.2528 - val_accuracy: 0.9763 - val_loss: 0.1254\n",
      "Epoch 50/50\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9020 - loss: 0.2455 - val_accuracy: 0.9640 - val_loss: 0.1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.fit(x = x_train[:7000], y = y_train[:7000], batch_size = batch_size, verbose=1, epochs=epochs, validation_data=(x_train[:3000], y_train[:3000]))\n",
    "\n",
    "model.save('models.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import underthesea\n",
    "\n",
    "# Chuẩn hóa các từ viết tắt\n",
    "abbreviation_dict = {\n",
    "    'k': 'không',\n",
    "    'ko': 'không',\n",
    "    'k0': 'không',\n",
    "    'bt': 'bình thường',\n",
    "    'ntn': 'như thế nào',\n",
    "    # Thêm các từ viết tắt khác nếu cần\n",
    "}\n",
    "\n",
    "# Hàm xử lý tiền xử lý văn bản\n",
    "def pre_process(text):\n",
    "    # 1. Chuyển về chữ thường\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Thay thế các URL bằng nhãn 'link_spam'\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', 'link_spam', text, flags=re.MULTILINE)\n",
    "\n",
    "    # 3. Xử lý các trường hợp lặp âm tiết (ví dụ: Ngoooon quááááá)\n",
    "    text = re.sub(r'(.)\\1+', r'\\1', text)  # Loại bỏ âm tiết lặp lại nhiều lần\n",
    "\n",
    "    # 4. Chuẩn hóa các từ viết tắt\n",
    "    words = text.split()\n",
    "    text = ' '.join([abbreviation_dict.get(word, word) for word in words])\n",
    "\n",
    "    # 5. Loại bỏ dấu câu và các ký tự đặc biệt\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # 6. Loại bỏ số và các từ chỉ có 1 ký tự\n",
    "    text = ' '.join([word for word in text.split() if len(word) > 1 and not word.isdigit()])\n",
    "\n",
    "    # 7. Tách từ sử dụng Underthesea\n",
    "    text = underthesea.word_tokenize(text, format=\"text\")\n",
    "\n",
    "    return text\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "text = \"đồ ăn ở đây vừa nhiều vừa ngon!!! Ngooon quááááá ơiiii! http://example.com\"\n",
    "text = pre_process(text)\n",
    "\n",
    "# In ra kết quả tiền xử lý\n",
    "print(\"Text sau tiền xử lý: \", text)\n",
    "\n",
    "# Tiếp tục với việc nhúng (embedding) và dự đoán như đã có\n",
    "maxtrix_embedding = np.expand_dims(comment_embedding(text), axis=0)\n",
    "maxtrix_embedding = np.expand_dims(maxtrix_embedding, axis=3)\n",
    "\n",
    "result = model.predict(maxtrix_embedding)\n",
    "result = np.argmax(result)\n",
    "print(\"Label predict: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danh sách các mẫu\n",
    "samples = [\n",
    "    \"Thật tuyệt vời!\",   # positive\n",
    "    \"Mọi thứ đều ổn.\",   # neutral\n",
    "    \"Tôi không thích nó.\", # negative\n",
    "    \"Đồ ăn ngon quá!\",   # positive\n",
    "    \"Có thể chấp nhận được.\", # neutral\n",
    "    \"Quá tệ!\",           # negative\n",
    "    \"Mọi thứ thật tuyệt vời!\", # positive\n",
    "    \"Chỉ bình thường thôi.\", # neutral\n",
    "    \"Tôi rất thất vọng.\"  # negative\n",
    "]\n",
    "\n",
    "# Tiền xử lý và dự đoán cho từng mẫu\n",
    "for text in samples:\n",
    "    processed_text = pre_process(text)\n",
    "    print(\"Text sau tiền xử lý: \", processed_text)\n",
    "\n",
    "    # Nhúng (embedding) và dự đoán\n",
    "    maxtrix_embedding = np.expand_dims(comment_embedding(processed_text), axis=0)\n",
    "    maxtrix_embedding = np.expand_dims(maxtrix_embedding, axis=3)\n",
    "\n",
    "    result = model.predict(maxtrix_embedding)\n",
    "    label = np.argmax(result)\n",
    "    print(\"Label predict: \", label) # 0:neutral, 1:positive, 2:negative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
